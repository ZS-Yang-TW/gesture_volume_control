{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "422ddfe4",
   "metadata": {},
   "source": [
    "# 【事前準備】使用 pyenv 建立 Python 3.9 虛擬環境\n",
    "## Python\n",
    "Python 建議版本 : 3.9 \n",
    "\n",
    "因為現在 Python 3.9 已經不是主要版本了，不過你可以使用 pyenv 來指定虛擬環境，安裝步驟如下：\n",
    "\n",
    "（以下都是 bash 指令）\n",
    "\n",
    "1. 使用 pip 安裝 pyenv。\n",
    "    ```bash\n",
    "    pip install pyenv-win --target $HOME/.pyenv\n",
    "    ```\n",
    "\n",
    "2. 設定環境變數。\n",
    "    ```bash\n",
    "    export PYENV=\"$HOME/.pyenv/pyenv-win/\"\n",
    "    export PYENV_HOME=\"$HOME/.pyenv/pyenv-win/\"\n",
    "    export PATH=\"$HOME/.pyenv/pyenv-win/bin:$HOME/.pyenv/pyenv-win/shims:$PATH\"\n",
    "    ```\n",
    "\n",
    "3. 驗證 pyenv 有沒有安裝成功。\n",
    "    ```bash\n",
    "    pyenv --version\n",
    "    ```\n",
    "\n",
    "4. pyenv 安裝成功後，就可以指定環境的版本。\n",
    "    ```bash\n",
    "    pyenv local 3.9.8\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48c595e",
   "metadata": {},
   "source": [
    "# 【事前準備】建立資料夾\n",
    "* Step1 : 在\"桌面\"建立新資料夾，取名\"gesture_control_project\"\n",
    "* Step2 : 開啟VScode，將\"gesture_control_project\"這個資料夾拉到工作區\n",
    "* Step3 : 在工作區右鍵，\"新增檔案\"，取名\"gesture_volume_control.py\"\n",
    "*** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a342b40",
   "metadata": {},
   "source": [
    "# 【事前準備】安裝套件!\n",
    "請在終端機輸入以下指令\n",
    "\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16dadee9",
   "metadata": {},
   "source": [
    "# 【PART1 打開電腦的靈魂之窗-讀取鏡頭】\n",
    "## 引入函式庫\n",
    "* 點開\"gesture_volume_control.py\"，開始編輯\n",
    "* 首先，我們要將我們可能會用到的套件都引入進來。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fb8b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2  #opencv 影像處理的套件\n",
    "import numpy as np #矩陣運算\n",
    "import time #用來取得電腦時間\n",
    "import mediapipe as mp #偵測模型\n",
    "import math #偵測模型\n",
    "\n",
    "\n",
    "#實現音量控制所需的套件:\n",
    "from ctypes import cast, POINTER\n",
    "from comtypes import CLSCTX_ALL\n",
    "from pycaw.pycaw import AudioUtilities, IAudioEndpointVolume    #音量控制套件\n",
    "# import osascript #音量控制套件 (For macOS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64b7d1e",
   "metadata": {},
   "source": [
    "## (1)讀取鏡頭，並顯示出來\n",
    "引入我們需要使用的工具後，就開始實作吧!\n",
    "\n",
    "* 首先，我們要先取得攝影機的影像。並且可以用cap.set()調整長寬。\n",
    "    ```python\n",
    "    ##攝影機設定##\n",
    "    cam_width , cam_height = 640, 480\n",
    "    cap = cv2.VideoCapture(0) # 填入0或1試試看\n",
    "    cap.set(3, cam_width)   # 調整影像寬度\n",
    "    cap.set(4, cam_height)   # 調整影像長度\n",
    "    ```\n",
    "\n",
    "* 接下來，建立一個不斷執行的while迴圈。\n",
    "* `cap.read()`這個函式可以回傳`ret`, `img`兩個值。`ret`: 有沒有回傳資料(0:沒有，1:有)，以及`img`:影像資料。\n",
    "* 如果 ret 存在，那麼就可以用`cv2.imshow()`這個函式開啟一個叫做'img'的視窗，將img這個影像顯示出來!\n",
    "* **ord('q')**的意思等同於\"在鍵盤上按q(注意是小寫喔!)\"。所以，**if cv2.waitKey(10) & 0xFF == ord('q')**意思就是，如果我按了q，就終止while迴圈，讓程式中止!\n",
    "\n",
    "    ```python\n",
    "    while True:\n",
    "        ret, img = cap.read()\n",
    "        if ret:\n",
    "            cv2.imshow('img', img) #顯示畫面\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "    ```\n",
    "\n",
    "#### 📁為什麼要& 0xFF:\n",
    "問得好!\n",
    "\n",
    "`cv2.waitkey`是OpenCV內置的函式，用途是在給定的時間內（單位毫秒）等待使用者的按鍵觸發，否則持續循環。\n",
    "ord(' ')可以將字符轉化為對應的整數（ASCII碼）。\n",
    "\n",
    "0xFF是十六進制常數，二進制值為11111111。這個寫法只留下原始的最後8位，和後面的ASCII碼對照。\n",
    "\n",
    "\n",
    "總之此處是為了防止BUG~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53477236",
   "metadata": {},
   "outputs": [],
   "source": [
    "##攝影機設定##\n",
    "cam_width , cam_height = 640, 480\n",
    "cap = cv2.VideoCapture(0) #填入0或1試試看\n",
    "cap.set(3, cam_width)   #調整影像寬度\n",
    "cap.set(4, cam_height)   #調整影像長度\n",
    "\n",
    "##迴圈區域##\n",
    "while True:\n",
    "    ret, img = cap.read()\n",
    "    \n",
    "    if ret:\n",
    "        cv2.imshow('img', img) #顯示畫面\n",
    "\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef6b667",
   "metadata": {},
   "source": [
    "### 執行結果: \n",
    "> <img src=\"./pic/read_success.png\" width=\"40%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c15baa",
   "metadata": {},
   "source": [
    "# 【PART2 實現即時手部偵測】\n",
    "\n",
    "## (1)mediapipe手部偵測模型設定\n",
    "* 讀取到鏡頭後，就可以進入主題囉!! ><\n",
    "* **在迴圈前面**，我們從mediapipe中引用他們的類別（class），存到一個叫做`mphands`的變數中\n",
    "* 從這個模型中，我們設定好手部辨識模型的參數，存到一個叫做`hands`的變數中。(hands的參數有很多，之後我們再來玩玩看。)\n",
    "* 我們也引用mediapipe中的繪畫工具，存到一個叫做`mpDraw`的變數中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0e3b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "##手部模型偵測參數設定、功能引入##\n",
    "mphands = mp.solutions.hands  #使用mediapipe裡的手部辨識功能\n",
    "hands = mphands.Hands(min_detection_confidence=0.5,min_tracking_confidence=0.5) #設定手部辨識模型\n",
    "mpDraw = mp.solutions.drawing_utils #繪畫工具"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4034422",
   "metadata": {},
   "source": [
    "## (2)於迴圈中使用手部偵測模型\n",
    "\n",
    "* 手部偵測需要偵測的是RGB的圖片，但因為 opencv 讀到的圖片都式 BGR 型式的圖片。\n",
    "* 所以要先用`img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)`讓BGR的圖片，轉換成RGB的形式。\n",
    "* 接下來把處理好的圖片(img_rgb)，利用`hands.process()`放到手部偵測模型當中，並把得到的結果用result存起來。\n",
    "\n",
    "\n",
    "* result裡面存了很多資料，其中我們可以用.multi_hand_landmarks，去讀取手部 21 個座標`(x,y,z)`的串列。\n",
    "* print出來會看到一堆字。如果印出`None`表示沒有偵測到手。\n",
    "\n",
    "#### 📁為什麼要用BGR，RGB不是比較常見嗎??:\n",
    "以前的年代比較常使用 BGR，因此 opencv 這個套件也使用了 BGR 模式。雖然現在 RGB 模式比較流行了，但 opencv 開發已久，一時間要改回來很~~~麻煩。\n",
    "\n",
    "所以正所謂:「前人種樹，後人乘涼」，如果沒特別原因，應該不需要砍了那棵樹打掉重練吧ww\n",
    "\n",
    "https://www.zhihu.com/question/264044792"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fe3cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##迴圈區域##\n",
    "while True:\n",
    "    ret, img = cap.read()       #讀取鏡頭\n",
    "    \n",
    "    if ret:\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)      #bgr轉rgb\n",
    "        result = hands.process(img_rgb)\n",
    "        print(result.multi_hand_landmarks)\n",
    "        \n",
    "        cv2.imshow('img', img) #顯示畫面\n",
    "\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deae6f29",
   "metadata": {},
   "source": [
    "## (3)畫出座標點\n",
    "* 有了座標之後，就可以在視窗的影像上把點點畫出來。\n",
    "* 自己寫程式畫出來可能有點麻煩，剛好mediapipe也有提供畫點的函式！ （讚🎉🎉\n",
    "* 我們剛剛已經把這個工具存在`mpdraw`了，我們直接使用他吧！\n",
    "\n",
    "\n",
    "* 我們先寫一個迴圈，如果有偵測到手，用for迴圈把每一隻手（用`handLams`當index）的點點畫出來。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26713b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "##迴圈區域##\n",
    "while True:\n",
    "    ret, img = cap.read()       #讀取鏡頭\n",
    "    \n",
    "    if ret:\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)      #bgr轉rgb\n",
    "        result = hands.process(img_rgb)\n",
    "        #print(result.multi_hand_landmarks)\n",
    "\n",
    "        if result.multi_hand_landmarks:\n",
    "            for handLms in result.multi_hand_landmarks:     #畫出每個手的座標及連線、設定樣式\n",
    "                mpDraw.draw_landmarks(img, handLms)\n",
    "        \n",
    "        cv2.imshow('img', img) #顯示畫面\n",
    "\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "## [執行看看] ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bb7ea8",
   "metadata": {},
   "source": [
    "### 執行結果: \n",
    "> <img src=\"./pic/red_spot.png\" width=\"40%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57dcf473",
   "metadata": {},
   "source": [
    "## (4)畫出骨架（連接座標點）\n",
    "* 只有點點看起來實在很像十八銅人的穴位圖... 所以，我們趕快把骨架連起來吧!\n",
    "* 這時在`mpDraw.draw_landmarks()`函式中，加入第三個參數`mphands.HAND_CONNECTIONS`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b8f365",
   "metadata": {},
   "outputs": [],
   "source": [
    "##迴圈區域##\n",
    "while True:\n",
    "    ret, img = cap.read()       #讀取鏡頭\n",
    "    \n",
    "    if ret:\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)      #bgr轉rgb\n",
    "        result = hands.process(img_rgb)\n",
    "        #print(result.multi_hand_landmarks)\n",
    "\n",
    "        if result.multi_hand_landmarks:\n",
    "            for handLms in result.multi_hand_landmarks:     #畫出每個手的座標及連線、設定樣式\n",
    "                mpDraw.draw_landmarks(img, handLms,mphands.HAND_CONNECTIONS)\n",
    "        \n",
    "        cv2.imshow('img', img) #顯示畫面\n",
    "\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98ee5d2",
   "metadata": {},
   "source": [
    "### 執行結果: \n",
    "> <img src=\"./pic/connection.png\" width=\"40%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32aa4aa3",
   "metadata": {},
   "source": [
    "# 【PART3 樣式調整、加上標號】\n",
    "## (1)樣式設定\n",
    "* 如果大家有點設計涵養，覺得點點跟線的樣式太醜，可以加入第四個參數（點的樣式），第五個參數（線的樣式）\n",
    "* 不過，這裡設定樣式的方式比較特別，我們要先寫一個**樣式設定**在while迴圈前面。\n",
    "* 利用`mpDraw.DrawingSpec()`我們可以設定座標點及連接線的顏色、粗細。\n",
    "\n",
    "\n",
    "* 然後，我再將`handLms_style`、`handCon_style`放到`mpDraw.draw_landmarks()`函式中\n",
    "\n",
    "    ```python\n",
    "    mpDraw.draw_landmarks(img, handLms,mphands.HAND_CONNECTIONS, handLms_style, handCon_style)\n",
    "    ```\n",
    "\n",
    "⚠️注意，這邊的顏色設定是BGR模式喔~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76b18aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "##手部骨架樣式設定##\n",
    "handLms_style = mpDraw.DrawingSpec(color=(73,93,70), thickness=6)  #手座標樣式\n",
    "handCon_style = mpDraw.DrawingSpec(color=(255,250,240), thickness=3) #手連接樣式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21eabf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "##迴圈區域##\n",
    "while True:\n",
    "    ret, img = cap.read()       #讀取鏡頭\n",
    "    \n",
    "    if ret:\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)      #bgr轉rgb\n",
    "        result = hands.process(img_rgb)\n",
    "        #print(result.multi_hand_landmarks)\n",
    "\n",
    "        if result.multi_hand_landmarks:\n",
    "            for handLms in result.multi_hand_landmarks:     #畫出每個手的座標及連線、設定樣式\n",
    "                mpDraw.draw_landmarks(img, handLms,mphands.HAND_CONNECTIONS, handLms_style, handCon_style)\n",
    "        \n",
    "        cv2.imshow('img', img) #顯示畫面\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcbd36a",
   "metadata": {},
   "source": [
    "### 執行結果: \n",
    "> <img src=\"./pic/color.png\" width=\"40%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa767de2",
   "metadata": {},
   "source": [
    "## （2）加上標號\n",
    "* 現在我們都把手的座標點跟連接線畫出來了。\n",
    "* 但我們要知道座標，才可以做各種應用嘛。所以接下來，就是要把 21 個點的座標找出來!!\n",
    "\n",
    "\n",
    "* `handLms.landmark`當中，存了 21 個點的 x 座標及 y 座標。\n",
    "* 我們用一個 for 迴圈，搭配列舉 `enumerate()` 函式，把每一隻手的 21 個座標 print 出來。\n",
    "\n",
    "    ```python\n",
    "    for i, lm in enumerate(handLms.landmark):       #輸出每個手的座標點 \n",
    "        print(i, lm.x, lm.y)\n",
    "    ```\n",
    "\n",
    "#### 📁列舉函式 enumerate( ):\n",
    "函式`enumerate()`是以 index 為索引，將串列、元組或字串中的數據列出來，一般用於for迴圈。\n",
    "https://www.runoob.com/python/python-func-enumerate.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a74fc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "##迴圈區域##\n",
    "while True:\n",
    "    ret, img = cap.read()       #讀取鏡頭\n",
    "    \n",
    "    if ret:\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)      #bgr轉rgb\n",
    "        result = hands.process(img_rgb)\n",
    "        #print(result.multi_hand_landmarks)\n",
    "\n",
    "        if result.multi_hand_landmarks:\n",
    "            for handLms in result.multi_hand_landmarks:     #畫出每個手的座標及連線、設定樣式\n",
    "                mpDraw.draw_landmarks(img, handLms,mphands.HAND_CONNECTIONS, handLms_style, handCon_style)\n",
    "                \n",
    "                for i, lm in enumerate(handLms.landmark):       #輸出每個手的座標點 \n",
    "                    print(i, lm.x, lm.y)\n",
    "        \n",
    "        cv2.imshow('img', img) #顯示畫面\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e731b91",
   "metadata": {},
   "source": [
    "* 我們確認一下，可以發現我們印出了 0 到 20 的座標點。但這個座標有一點怪怪的，數值都在 0 到 1 之間。\n",
    "* 其實，這個數值指是**比例**。假設我們畫面是 100*100，那 0.6 就大概在寬度 60 的地方\n",
    "* 所以要得到真正的座標，只要**乘上視窗的高度跟寬度**即可。\n",
    "\n",
    "\n",
    "* 在img裡面**img.shape[0]存了影像的寬，img.shape[1]存了影像的高**。\n",
    "\n",
    "* 我們先在 if result.multi_hand_landmarks:這個判斷迴圈外，設定這兩個變數:\n",
    "\n",
    "    ```python\n",
    "    img_height = img.shape[0]  #得到影像的高\n",
    "    img_width = img.shape[1]   #得到影像的寬\n",
    "    ```\n",
    "\n",
    "        \n",
    "\n",
    "* 然後，回去 enumerte() 迴圈，將 x, y 比例座標分別乘上寬度與長度，並且用`int()`取整函數得到整數。得到的`xPos`, `yPos` 也就是真正影像上的座標位置。\n",
    "\n",
    "    ```python\n",
    "    xPos = int(lm.x * img_width)    #比例乘上寬度\n",
    "    yPos = int(lm.y * img_height)   #比例乘上高度\n",
    "    print(i, xPos, yPos)\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcdeea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "##迴圈區域##\n",
    "while True:\n",
    "    ret, img = cap.read()       #讀取鏡頭\n",
    "    \n",
    "    if ret:\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)      #bgr轉rgb\n",
    "        result = hands.process(img_rgb)\n",
    "        #print(result.multi_hand_landmarks)\n",
    "        \n",
    "        img_height = img.shape[0]  #得到影像的高\n",
    "        img_width = img.shape[1]   #得到影像的寬\n",
    "\n",
    "        if result.multi_hand_landmarks:\n",
    "            for handLms in result.multi_hand_landmarks:     #畫出每個手的座標及連線、設定樣式\n",
    "                mpDraw.draw_landmarks(img, handLms,mphands.HAND_CONNECTIONS, handLms_style, handCon_style)\n",
    "                \n",
    "                for i, lm in enumerate(handLms.landmark):       #輸出每個手的座標點 \n",
    "                    xPos = int(lm.x * img_width)    #比例乘上寬度\n",
    "                    yPos = int(lm.y * img_height)   #比例乘上高度\n",
    "                    print(i, xPos, yPos)\n",
    "        \n",
    "        cv2.imshow('img', img) #顯示畫面\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0461fc8f",
   "metadata": {},
   "source": [
    "* 有了座標後，我們用就可以用cv2.putText()這個函式，把座標數字標上去!\n",
    "* **cv2.putText(放在哪張圖, 要放的文字, 座標, 字形, 顏色, 粗細)**\n",
    "\n",
    "    ```python\n",
    "    cv2.putText(img, str(i), (xPos-25, yPos+5), cv2.FONT_HERSHEY_COMPLEX, 0.4, (0,69,255), 1)   #加上標籤\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abd4801",
   "metadata": {},
   "outputs": [],
   "source": [
    "##迴圈區域##\n",
    "while True:\n",
    "    ret, img = cap.read()       #讀取鏡頭\n",
    "    \n",
    "    if ret:\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)      #bgr轉rgb\n",
    "        result = hands.process(img_rgb)\n",
    "        #print(result.multi_hand_landmarks)\n",
    "        \n",
    "        img_height = img.shape[0]  #得到影像的高\n",
    "        img_width = img.shape[1]   #得到影像的寬\n",
    "\n",
    "        if result.multi_hand_landmarks:\n",
    "            for handLms in result.multi_hand_landmarks:     #畫出每個手的座標及連線、設定樣式\n",
    "                mpDraw.draw_landmarks(img, handLms,mphands.HAND_CONNECTIONS, handLms_style, handCon_style)\n",
    "                \n",
    "                for i, lm in enumerate(handLms.landmark):       #輸出每個手的座標點 \n",
    "                    xPos = int(lm.x * img_width)    #比例乘上寬度\n",
    "                    yPos = int(lm.y * img_height)   #比例乘上高度\n",
    "                    cv2.putText(img, str(i), (xPos-25, yPos+5), cv2.FONT_HERSHEY_COMPLEX, 0.4, (0,69,255), 1)   #加上標籤\n",
    "        \n",
    "        cv2.imshow('img', img) #顯示畫面\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc59aff",
   "metadata": {},
   "source": [
    "## （3）把大拇指的點點畫上去。\n",
    "* 觀察一下，第 4、8、12、16、20 個點，分別是哪個部位?\n",
    "* Ans: 一定是大拇指的啦!👍️👍️👍️👍️\n",
    "\n",
    "\n",
    "* 如果我們要特別標註這些點，可以用cv2.circle()直接在第四點畫一個圈。\n",
    "* **cv2.circle(畫在哪裡, 座標, 半徑, 顏色, 粗度可以直接填滿)**\n",
    "* 現在把所有手指頭都填滿吧!! (補充: | 這個標號是邏輯中的\"或\"的意思)\n",
    "\n",
    "    ```python\n",
    "    if (i == 4)|(i == 8)|(i == 12)|(i == 16)|(i == 20):  \n",
    "        cv2.circle(img, (xPos, yPos), 9, (34,139,34), cv2.FILLED)\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f4a892",
   "metadata": {},
   "outputs": [],
   "source": [
    "##迴圈區域##\n",
    "while True:\n",
    "    ret, img = cap.read()       #讀取鏡頭\n",
    "    \n",
    "    if ret:\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)      #bgr轉rgb\n",
    "        result = hands.process(img_rgb)\n",
    "        #print(result.multi_hand_landmarks)\n",
    "        \n",
    "        img_height = img.shape[0]  #得到影像的高\n",
    "        img_width = img.shape[1]   #得到影像的寬\n",
    "\n",
    "        if result.multi_hand_landmarks:\n",
    "            for handLms in result.multi_hand_landmarks:     #畫出每個手的座標及連線、設定樣式\n",
    "                mpDraw.draw_landmarks(img, handLms,mphands.HAND_CONNECTIONS, handLms_style, handCon_style)\n",
    "                \n",
    "                for i, lm in enumerate(handLms.landmark):       #輸出每個手的座標點 \n",
    "                    xPos = int(lm.x * img_width)    #比例乘上寬度\n",
    "                    yPos = int(lm.y * img_height)   #比例乘上高度\n",
    "                    cv2.putText(img, str(i), (xPos-25, yPos+5), cv2.FONT_HERSHEY_COMPLEX, 0.4, (0,69,255), 1)   #加上標籤\n",
    "                    \n",
    "                    # 畫拇指!\n",
    "                    if (i == 4)|(i == 8)|(i == 12)|(i == 16)|(i == 20):  \n",
    "                        cv2.circle(img, (xPos, yPos), 9, (34,139,34), cv2.FILLED)\n",
    "        \n",
    "        cv2.imshow('img', img) #顯示畫面\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8f2e30",
   "metadata": {},
   "source": [
    "### 執行結果: \n",
    "> <img src=\"./pic/complete.png\" width=\"40%\">\n",
    "\n",
    "### 完成後，幫自己比一個讚吧!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8a0a3e",
   "metadata": {},
   "source": [
    "# 【PART4 DJ Drop The Beat-用手勢控制音量大小!】\n",
    "* 如果把上面的實作出來，就可以實現很多功能喔!\n",
    "* 這邊教你做一個可以用手勢調整音樂音量專案，沒當過 DJ 沒關係，這次體驗一次XD!\n",
    "\n",
    "#### P.S. 其實還有很多功用啦~ 像是智能健身教練、手語辨識、簡易音遊，只要妥當設計，這個真的超好玩der"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acd9b34",
   "metadata": {},
   "source": [
    "## (1)設計專案需求\n",
    "* 在做任何專案以前，先思考自己有哪些**\"功能需求\"**，並且思考**\"要如何以程式實現\"**。\n",
    "\n",
    "\n",
    "* 以下是這次專案會想要的東西:\n",
    "1. **顯示幀率（frame rate）:** 為了判斷我的畫面有沒有很卡，所以想要放上去\n",
    "2. **音量指示條:** 有個指示條感覺比較直觀、清楚，看起來也更炫(?)\n",
    "3. **音量百分比:** 可以確切看到音量大小的數值。\n",
    "4. **拇指跟食指連線:** 因為想要用\"拇指跟食指的距離\"，來調整音樂的大小聲。\n",
    "5. **中點:** 想要在\"最大聲\"及\"最小聲\"的時候，讓中點變顏色來給予提醒。\n",
    "\n",
    "\n",
    "* 除了設計**邏輯功能**之外，也要思考如何將這些東西**可視化**喔!\n",
    "\n",
    "> <img src=\"./pic/design.png\" width=\"80%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3e496b",
   "metadata": {},
   "source": [
    "* **在進到下個part之前，可以先跟同學討論看看可以怎麼修改原本的程式碼，實現這個專案!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e88a23",
   "metadata": {},
   "source": [
    "# 【PART5 各項參數的初始化設定】\n",
    "* 在while迴圈前，我們要加入一些初始化設定。\n",
    "\n",
    "## (1) 幀率的參數設定\n",
    "* 為了要計算每秒有多少幀，我需要記錄現在的時間點(current_time)，還有上個時間點(previous_time)。\n",
    "* 至於如何計算，會在後面解釋~\n",
    "\n",
    "    ```python\n",
    "    ##FPS計算參數設定##\n",
    "    current_time = 0\n",
    "    previous_time = 0\n",
    "    ```\n",
    "\n",
    "## (2)音量控制相關設定\n",
    "* 用**vol、volbar、volper**分別記錄**音量大小、音量指示條、音量百分比**的數值。\n",
    "\n",
    "    ```python\n",
    "    ##音量控制相關設定##\n",
    "    vol = 0 #初始化音量大小\n",
    "    volbar = 400 #初始化音量指示條頂的位置\n",
    "    volper = 0  #初始化音量百分比數值\n",
    "    ```\n",
    "\n",
    "## (3)取得裝置的音量範圍\n",
    "* 取得裝置的音源。這部分暫時不用理解，直接複製貼上即可~\n",
    "\n",
    "    ```python\n",
    "    ##取得裝置的音量範圍##\n",
    "    devices = AudioUtilities.GetSpeakers()\n",
    "    interface = devices.Activate(IAudioEndpointVolume._iid_, CLSCTX_ALL, None)\n",
    "    volume = cast(interface, POINTER(IAudioEndpointVolume))\n",
    "    ```\n",
    "\n",
    "\n",
    "* 利用**volume.GetVolumeRange()**可以取得裝置音量範圍資料，其中音量最小值存在volRange[0]，最大值存在volRange[1]\n",
    "* 我們把它print出來，記錄在註解裡。\n",
    "\n",
    "    ```python\n",
    "    volRange = volume.GetVolumeRange()  #取得裝置音量範圍資料\n",
    "    minVol, maxVol = volRange[0], volRange[1]   #取得裝置音量最大值、最小值\n",
    "    print(volume.GetVolumeRange())  #輸出音量範圍   (-96,0,後面這個不用理他)\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2926a350",
   "metadata": {},
   "outputs": [],
   "source": [
    "##FPS計算參數設定##\n",
    "current_time = 0\n",
    "previous_time = 0\n",
    "\n",
    "##音量控制相關設定##\n",
    "vol = 0 #初始化音量大小\n",
    "volbar = 400 #初始化音量指示條頂的位置\n",
    "volper = 0  #初始化音量百分比數值\n",
    "\n",
    "##取得裝置的音量範圍##\n",
    "devices = AudioUtilities.GetSpeakers()\n",
    "interface = devices.Activate(IAudioEndpointVolume._iid_, CLSCTX_ALL, None)\n",
    "volume = cast(interface, POINTER(IAudioEndpointVolume))\n",
    "\n",
    "volRange = volume.GetVolumeRange()  #取得裝置音量範圍資料\n",
    "minVol, maxVol = volRange[0], volRange[1]   #取得裝置音量最大值、最小值\n",
    "print(volume.GetVolumeRange())  #輸出音量範圍   (-96,0,後面這個不用理他)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a61f7b",
   "metadata": {},
   "source": [
    "# 【PART6 控制功能設計】\n",
    "* 將參數初始化之後，就可以開始設計功能的程式囉！\n",
    "\n",
    "## （1）計算拇指、食指兩點的長度，並設定觸發事件\n",
    "* 跟著下圖的步驟，我們一步步修改原本的程式碼。\n",
    "> <img src=\"./pic/event.png\" width=\"80%\">\n",
    "\n",
    "\n",
    "* 在記錄座標點的迴圈內，我們需要取得**\"第四點\"跟\"第八點\"的座標**。\n",
    "\n",
    "    ```python\n",
    "    #記錄拇指與食指座標\n",
    "    if (i == 4):\n",
    "        x4, y4 = xPos, yPos\n",
    "    if (i == 8):\n",
    "        x8, y8 = xPos, yPos\n",
    "    ```\n",
    "\n",
    "* 在記錄座標點的迴圈外面，計算**中點座標**。然後**計算拇指、食指兩點的長度**。\n",
    "\n",
    "    ```python\n",
    "    xm , ym = (x4+x8)//2 , (y4+y8)//2   #取得中點座標\n",
    "\n",
    "    #計算拇指、食指兩點的長度，並設定觸發事件\n",
    "    length = math.hypot(x8-x4, y8-y4)   #用square root計算長度\n",
    "    ```\n",
    "\n",
    "* 在畫手的迴圈外面，設定觸發事件。\n",
    "\n",
    "    ```python\n",
    "    if (length <= 25)|(length >= 200):        #手指捏起來的時候，中點變色 (設定觸發事件)\n",
    "        cv2.circle(img, (xm, ym), 9, (34,34,78), cv2.FILLED)\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b2ec4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##迴圈區域##\n",
    "while True:\n",
    "    ret, img = cap.read()\n",
    "    #hand_detection\n",
    "    if ret:\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)      #bgr轉rgb\n",
    "        result = hands.process(img_rgb)\n",
    "\n",
    "        img_height = img.shape[0]\n",
    "        img_width = img.shape[1]\n",
    "\n",
    "        if result.multi_hand_landmarks:\n",
    "            for handLms in result.multi_hand_landmarks:     #畫出每個手的座標及連線、設定樣式\n",
    "                mpDraw.draw_landmarks(img, handLms,mphands.HAND_CONNECTIONS, handLms_style, handCon_style)\n",
    "                    \n",
    "                for i, lm in enumerate(handLms.landmark):       #輸出每個手的座標點 \n",
    "                    xPos = int(lm.x * img_width)    #比例乘上寬度\n",
    "                    yPos = int(lm.y * img_height)   #比例乘上高度\n",
    "                    \n",
    "                    #記錄拇指與食指座標\n",
    "                    if (i == 4):\n",
    "                        x4, y4 = xPos, yPos\n",
    "                    if (i == 8):\n",
    "                        x8, y8 = xPos, yPos\n",
    "                \n",
    "                xm , ym = (x4+x8)//2 , (y4+y8)//2   #取得中點座標\n",
    "                \n",
    "                #計算拇指、食指兩點的長度，並設定觸發事件\n",
    "                length = math.hypot(x8-x4, y8-y4)   #用square root計算長度\n",
    "\n",
    "            if (length <= 25)|(length >= 200):        #手指捏起來的時候，中點變色 (設定觸發事件)\n",
    "                cv2.circle(img, (xm, ym), 9, (34,34,78), cv2.FILLED)\n",
    "                \n",
    "    cv2.imshow(\"img\",img)\n",
    "\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4176d7b9",
   "metadata": {},
   "source": [
    "## (2)映射調整\n",
    "* 接下來想想看，如何用\"手張多大\"去影響\"音量多大聲\"、\"指示條多長\"、\"百分比數字多大\"呢?\n",
    "* 像這種從**\"某個變數\"去對應到\"另一個變數\"**的關係我們在數學上稱為**「映射」**。跟函數關係很類似!\n",
    "\n",
    "> <img src=\"./pic/mapping.png\" width=\"80%\">\n",
    "\n",
    "* 我們這次用的方法叫做**「線性插值法」**，有興趣的同學下面資料可以點進去看。\n",
    "* np.interp()這個函式可以在給予\"拇指與食指長度\"後，自動輸出一個在\"特定範圍內\"的數值。\n",
    "* 舉例: 長度為 105 時，音量百分比對應到的是 45%。\n",
    "\n",
    "    ```python\n",
    "    vol = np.interp(length,[25,200],[-30,maxVol])   #音量映射調整\n",
    "    volbar = np.interp(length,[25,200],[400,150])   #指示條長度映射調整\n",
    "    volper = np.interp(length,[25,200],[0,100])   #指示條數值映射調整\n",
    "    ```\n",
    "\n",
    "* 而音量設定的部分，就用volume.SetMasterVolumeLevel(vol, None)來實現!\n",
    "\n",
    "    ```python\n",
    "    volume.SetMasterVolumeLevel(vol, None)  #設定音量\n",
    "    ```\n",
    "\n",
    "\n",
    "#### 📁線性插值:\n",
    "https://zh.wikipedia.org/zh-tw/%E7%BA%BF%E6%80%A7%E6%8F%92%E5%80%BC\n",
    "#### 📁numpy.interp()用法:\n",
    "https://blog.csdn.net/hfutdog/article/details/87386901"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000a6fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#映射調整\n",
    "            vol = np.interp(length,[25,200],[-30,maxVol])   #音量映射調整\n",
    "            volbar = np.interp(length,[25,200],[400,150])   #指示條長度映射調整\n",
    "            volper = np.interp(length,[25,200],[0,100])   #指示條數值映射調整\n",
    "            volume.SetMasterVolumeLevel(vol, None)  #設定音量"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46778e3",
   "metadata": {},
   "source": [
    "## (3)計算幀率\n",
    "* 我們可能沒辦法直接計算一秒中有多少幀（frame），但一秒幾次不就是**「頻率」**的概念嗎?!\n",
    "* 那只要計算兩個畫面產生的週期是多長，再用「頻率為週期的倒數」，$F=\\frac{1}{T}$，就可以算出幀率囉!\n",
    "\n",
    "* 記得寫在**if ret:**這個判斷迴圈外。\n",
    "\n",
    "> <img src=\"./pic/fps.png\" width=\"80%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878c7901",
   "metadata": {},
   "outputs": [],
   "source": [
    "#計算幀率\n",
    "    current_time = time.time()  #取得當下的時間\n",
    "    fps = 1/(current_time-previous_time)    #算出\"週期\"，倒數後變成\"頻率\"\n",
    "    previous_time = current_time    #記錄當下的時間，當作下次算週期的參考。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62029a49",
   "metadata": {},
   "source": [
    "# 【PART7 功能可視化】\n",
    "* 把功能邏輯都做完之後，還是要讓功能以圖形、文字顯示出來，以便於讓使用者更方便理解與使用。這種概念稱為**「可視化（Visualization）」**。\n",
    "\n",
    "## （1）畫出拇指、食指、中點三個點，並連線。\n",
    "* 我們把拇指、食指、中點三個點畫上去，並把線連起來吧~\n",
    "* 記得**這段要加在觸發事件之前**喔!要不然觸發事件會被覆蓋掉~ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5ad4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "            #畫出拇指、食指、中指三個點，並連線\n",
    "            cv2.circle(img, (x4, y4), 9, (105,165,218), cv2.FILLED)\n",
    "            cv2.circle(img, (x8, y8), 9, (105,165,218), cv2.FILLED)\n",
    "            cv2.circle(img, (xm, ym), 9, (105,165,218), cv2.FILLED)\n",
    "            cv2.line(img,(x4, y4),(x8, y8),(105,165,218),3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3633ef",
   "metadata": {},
   "source": [
    "## (2)畫出指示框、指示條、顯示幀率、音量百分比\n",
    "* 最後，在**if ret:**這個判斷迴圈外，把指示框、指示條、幀率、音量百分比也加上去\n",
    "* 值得注意的是，`cv2.putText()` 函式中，填入字串參數中有變數存在，因此前面要使用格式化字符串 f-string\"，變數的部分以大括弧 {} 框住。\n",
    "\n",
    "#### 📁格式化的字串文本 (Formatted String Literals)\n",
    "https://docs.python.org/zh-tw/3/tutorial/inputoutput.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcd623d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#畫出指示框、指示條、顯示幀率、音量百分比\n",
    "    cv2.rectangle(img,(50,150),(85,400),(105,165,218),3)  #指示條外框\n",
    "    cv2.rectangle(img,(50,int(volbar)),(85,400),(105,165,218),cv2.FILLED)   #指示條填滿\n",
    "    cv2.putText(img,f\"FPS:{int(fps)}\",(30,50), cv2.FONT_HERSHEY_DUPLEX, 1.5, (49,68,52), 3)  #fps標籤\n",
    "    cv2.putText(img,f\"{int(volper)}%\",(40,450), cv2.FONT_HERSHEY_DUPLEX, 1,(105,165,218), 2)  #音量數值標籤"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c467dfa0",
   "metadata": {},
   "source": [
    "# 搭啦!大功告成囉!!!!!!!!~~🎊🎊🎉🎉🎉🥳🥳\n",
    "### 快點一首音樂來玩玩看吧!\n",
    "\n",
    "> <img src=\"./pic/final.png\" width=\"80%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d090cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "##迴圈區域##\n",
    "while True:\n",
    "    ret, img = cap.read()\n",
    "    #hand_detection\n",
    "    if ret:\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)      #bgr轉rgb\n",
    "        result = hands.process(img_rgb)\n",
    "\n",
    "        img_height = img.shape[0]\n",
    "        img_width = img.shape[1]\n",
    "\n",
    "        if result.multi_hand_landmarks:\n",
    "            for handLms in result.multi_hand_landmarks:     #畫出每個手的座標及連線、設定樣式\n",
    "                mpDraw.draw_landmarks(img, handLms,mphands.HAND_CONNECTIONS, handLms_style, handCon_style)\n",
    "                    \n",
    "                for i, lm in enumerate(handLms.landmark):       #輸出每個手的座標點 \n",
    "                    xPos = int(lm.x * img_width)    #比例乘上寬度\n",
    "                    yPos = int(lm.y * img_height)   #比例乘上高度\n",
    "                    \n",
    "                    #記錄拇指與食指座標\n",
    "                    if (i == 4):\n",
    "                        x4, y4 = xPos, yPos\n",
    "                    if (i == 8):\n",
    "                        x8, y8 = xPos, yPos\n",
    "                \n",
    "                xm , ym = (x4+x8)//2 , (y4+y8)//2   #取得中點座標\n",
    "                \n",
    "                #計算拇指、食指兩點的長度，並設定觸發事件\n",
    "                length = math.hypot(x8-x4, y8-y4)   #用square root計算長度\n",
    "                \n",
    "            #映射調整\n",
    "            vol = np.interp(length,[25,200],[-30,maxVol])   #音量映射調整\n",
    "            volbar = np.interp(length,[25,200],[400,150])   #指示條長度映射調整\n",
    "            volper = np.interp(length,[25,200],[0,100])   #指示條數值映射調整\n",
    "            volume.SetMasterVolumeLevel(vol, None)  #設定音量    \n",
    "                \n",
    "            #畫出拇指、食指、中指三個點，並連線\n",
    "            cv2.circle(img, (x4, y4), 9, (105,165,218), cv2.FILLED)\n",
    "            cv2.circle(img, (x8, y8), 9, (105,165,218), cv2.FILLED)\n",
    "            cv2.circle(img, (xm, ym), 9, (105,165,218), cv2.FILLED)\n",
    "            cv2.line(img,(x4, y4),(x8, y8),(105,165,218),3)\n",
    "            \n",
    "            if (length <= 25)|(length >= 200):        #手指捏起來的時候，中點變色 (設定觸發事件)\n",
    "                cv2.circle(img, (xm, ym), 9, (34,34,78), cv2.FILLED)\n",
    "    \n",
    "    #計算幀率\n",
    "    current_time = time.time()  #取得當下的時間\n",
    "    fps = 1/(current_time-previous_time)    #算出\"週期\"，倒數後變成\"頻率\"\n",
    "    previous_time = current_time    #記錄當下的時間，當作下次算週期的參考。\n",
    "    \n",
    "    #畫出指示框、指示條、顯示幀率、音量百分比\n",
    "    cv2.rectangle(img,(50,150),(85,400),(105,165,218),3)  #指示條外框\n",
    "    cv2.rectangle(img,(50,int(volbar)),(85,400),(105,165,218),cv2.FILLED)   #指示條填滿\n",
    "    cv2.putText(img,f\"FPS:{int(fps)}\",(30,50), cv2.FONT_HERSHEY_DUPLEX, 1.5, (49,68,52), 3)  #fps標籤\n",
    "    cv2.putText(img,f\"{int(volper)}%\",(40,450), cv2.FONT_HERSHEY_DUPLEX, 1,(105,165,218), 2)  #音量數值標籤    \n",
    "                \n",
    "    cv2.imshow(\"img\",img)\n",
    "\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f915732",
   "metadata": {},
   "source": [
    "## 延伸應用\n",
    "[Real Time Sign Language Detection with Tensorflow Object Detection and Python | Deep Learning SSD](https://www.youtube.com/watch?v=pDXdlXlaCco&t=137s&ab_channel=NicholasRenotte)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b83044019f24dd6a59c641ad64d62197b2c8e2bba96b67c3a471417d67d79ebd"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
